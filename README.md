# Multimedia_2semester

**Студент: Марченко Алексей Эдуардович**

**Группа: М8О-407Б-21**

## Выводы по лабораторной работе №6

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

| Модель                      | Accuracy | F1     | Precision | Recall | 
|:---------------------------:|:--------:|:------:|:---------:|:------:|
| VGG16 (before)              | 0.68     | 0.68   | 0.68      | 0.68   |
| VGG16 (after)               | 0.82     | 0.82   | 0.83      | 0.82   |
| ViT-B/16 (before)           | 0.24     | 0.22   | 0.24      | 0.24   |
| ViT-B/16 (after)            | 0.82     | 0.82   | 0.82      | 0.82   |
| Custom CNN (before)         | 0.61     | 0.61   | 0.61      | 0.61   |
| Custom CNN (after)          | 0.62     | 0.62   | 0.62      | 0.62   |
| Custom Transformer (before) | 0.43     | 0.43   | 0.45      | 0.43   |
| Custom Transformer (after)  | 0.62     | 0.62   | 0.62      | 0.62   |

После анализа представленных результатов видно, что улучшение бейзлайна оказало положительное влияние на все модели, однако степень этого влияния различается. Наиболее впечатляющий прирост наблюдается у кастомных моделей — как у сверточной (CNN), так и у трансформерной. Изначально они демонстрировали относительно скромные показатели (в районе 40–45% точности на тесте), однако после улучшения уверенно преодолели порог в 60%, а трансформерная модель и вовсе приблизилась к 63%. Это говорит о том, что изначальная настройка бейзлайна значительно сдерживала потенциал архитектуры, и после внесения изменений (возможно, улучшение аугментаций, оптимизации, регулирований или структуры данных) модели смогли раскрыться гораздо полнее.

Более зрелые и мощные архитектуры, такие как VGG16 и ViT-B/16, показали высокие результаты уже до улучшений, но всё равно выиграли от оптимизаций. У VGG16 рост составил около 4.6% в точности на тесте, а у ViT прирост оказался менее выраженным, что может свидетельствовать о близости изначального состояния к оптимальному для этой модели. Тем не менее, ViT всё равно оказался лидером среди всех моделей по абсолютным значениям метрик, демонстрируя максимальную стабильность и общую сбалансированность результатов.

Таким образом, можно заключить, что улучшения бейзлайна были особенно критичны для кастомных моделей, позволив им выйти на уровень качества, сравнимый с промышленными решениями. Для предобученных моделей эти улучшения сыграли скорее роль дополнительной доводки, а не ключевого фактора успеха, однако даже в этом случае они обеспечили ощутимый прирост.

## Выводы по лабораторной работе №7

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

В ходе экспериментов сравнивались библиотечные и кастомные реализации CNN и трансформеров для задачи семантической сегментации до и после улучшения бейзлайна.

| Модель                      | IoU      | Dice   | Precision | Recall | 
|:---------------------------:|:--------:|:------:|:---------:|:------:|
| CNN (before)                | 0.55     | 0.71   | 0.68      | 0.75   |
| CNN (after)                 | 0.67     | 0.80   | 0.80      | 0.80   |
| Transformer (before)        | 0.68     | 0.68   | 0.85      | 0.77   |
| Transformer (after)         | 0.69     | 0.81   | 0.86      | 0.77   |
| Custom CNN (before)         | 0.74     | 0.74   | 0.96      | 0.44   |
| Custom CNN (after)          | 0.73     | 0.78   | 0.96      | 0.46   |
| Custom Transformer (before) | 0.67     | 0.67   | 0.85      | 0.31   |
| Custom Transformer (after)  | 0.72     | 0.71   | 0.94      |	0.42   |

После доработки бейзлайна все модели показали рост метрик качества. Наилучшие значения IoU достигли кастомные модели: 
* Custom CNN — 0.73
* Custom Transformer — 0.72

Также кастомные модели показали высокие значения Precision (до 0.96), подтверждая точность предсказаний.

Библиотечные модели при этом демонстрировали более сбалансированные метрики по Recall и Dice, особенно в трансформере.

Таким образом, улучшение бейзлайна положительно сказалось на всех моделях, а кастомные решения оказались конкурентоспособными и в ряде случаев — лидирующими.

## Выводы по лабораторной работе №8

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

| Модель          | Precision | Recall | Confusion matrix | mAP   | 
|:---------------:|:---------:|:------:|:----------------:|:-----:|
| YOLOv11         | 1.0       | 1.0    | ideal            | 0.99  |
| YOLOv8          | 1.0       | 1.0    | ideal            | 0.99  |
| Custom          | 0.97      | 0.98   | small errors     | 0.0   |
| Improved Custom | 1.0       | 1.0    | ideal            | 0.48  |

На основе полученных результатов лабораторной работы можно сделать следующие выводы относительно производительности различных моделей для задачи обнаружения объектов:

1. YOLOv11 и YOLOv8:
  * Оба варианта YOLOv11 и YOLOv8 продемонстрировали идеальные результаты с Precision и Recall, равными 1.0000, что свидетельствует о том, что модели правильно классифицировали все объекты без ложных срабатываний.
  * Матрица ошибок для обеих моделей является идеальной, что подтверждает отсутствие ошибок классификации.
  * mAP этих моделей составил 0.995, что подтверждает высокую производительность как в задаче классификации, так и в задаче локализации объектов.
2. Custom модель:
  * Custom модель показала Precision = 0.97 и Recall = 0.98, что указывает на то, что модель достаточно хорошо справляется с задачей классификации и локализации объектов, но при этом имеет некоторые ошибки, что привело к небольшому снижению показателей по сравнению с YOLO моделями.
  * Матрица ошибок свидетельствует о наличии небольших ошибок, особенно в части локализации объектов.
  * mAP для этой модели составил 0.000, что указывает на проблемы с локализацией объектов, несмотря на хорошие результаты в классификации.
3. Improved Custom модель:
  * Improved Custom модель была улучшена для повышения результатов обучения, и это отразилось на Precision и Recall, которые теперь составляют 1.0000, что говорит о идеальных значениях в классификации объектов.
  * Матрица ошибок также является идеальной, что подтверждает, что модель теперь классифицирует все объекты правильно, без ошибок.
  * Важным улучшением является то, что mAP для улучшенной модели составил 0.485, что значительно выше, чем у Custom модели. Это говорит о том, что улучшения в обучении также положительно сказались на локализации объектов, несмотря на оставшиеся сложности.
    
**Резюме:**

YOLOv11 и YOLOv8 продемонстрировали наилучшие результаты во всех аспектах: точность классификации и локализации практически идеальна, а mAP близка к максимальному значению.

Custom модель показала хорошие результаты в классификации, но проблемы с локализацией привели к mAP = 0.000, что является значительным ограничением.

Improved Custom модель продемонстрировала значительное улучшение: Precision и Recall = 1.0000, а также увеличение mAP до 0.48, что указывает на улучшение локализации объектов по сравнению с Custom моделью.
